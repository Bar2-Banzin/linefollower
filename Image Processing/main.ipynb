{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All imports we will need\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt instead.\n"
     ]
    }
   ],
   "source": [
    "IN_DEBUG=False ## sets DEBUG false to avoid running assertions on incomplete requirements\n",
    "\n",
    "%run ./utils.ipynb  ## this line runs the utils notebook and imports it into the current notebook\n",
    "\n",
    "# use interactive plots\n",
    "%matplotlib notebook\n",
    "## you will need to re-run this cell every time you change something in the utils notebook\n",
    "## DONOT forget to save the utils notebook before running this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('imgs/image1.jpg')\n",
    "# # cv2.imshow('image', img)\n",
    "# # edit_image=preprocess(img)\n",
    "# # cv2.imshow('edit_image', edit_image)\n",
    "# gray_scale= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "# contours, hierarchy = cv2.findContours(gray_scale, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Img\n",
    "# img = cv2.imread('imgs/image4.jpg')\n",
    "img = cv2.imread('imgs/image4.jpg')\n",
    "\n",
    "\n",
    "#Convert To Gray Scale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Edge Detection [i/p must be gray Scale image]\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)#there is some noise here we need to remove it\n",
    "\n",
    "show_images([img,gray,edges],['Original','Gray Scale','Edged Image'])\n",
    "\n",
    "\n",
    "# Hough Lines Detection\n",
    "# To apply the Transform, first an edge detection pre-processing is desirable.\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=50)\n",
    "\n",
    "# Draw lines on the image\n",
    "Straight_Lines=np.copy(img)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(Straight_Lines, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "\n",
    "# Matrix of Endpoints and start points of the straight lines\n",
    "Straight_Lines_Matrix=np.ones(np.shape(img)[0:2])\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    Straight_Lines_Matrix[y1,x1]=0\n",
    "    Straight_Lines_Matrix[y2,x2]=0\n",
    "#     print('x1:',x1,'y1:',y1,'x2:',x2,'y2:',y2)\n",
    "# print(lines)\n",
    "\n",
    "show_images([Straight_Lines,Straight_Lines_Matrix],['Straight Lines','Straight Lines Matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "# Car Detetction :D\n",
    "\n",
    "#Read Img\n",
    "img = cv2.imread('imgs/1.jpeg')\n",
    "\n",
    "# For better accuracy, use binary images. So before finding contours, apply threshold or canny edge detection\n",
    "# Convert To Gray Scale\n",
    "binary = toBianry(img)\n",
    "\n",
    "# show_images([img,binary],['Original','Binary Image'])\n",
    "\n",
    "#Getting Contours in image\n",
    "# 1st parm: source image\n",
    "# 2nd parm: contour retrieval mode\n",
    "# 3rd parm: contour approximation method cv2.CHAIN_APPROX_SIMPLE[Memory saved not all points are stored]\n",
    "#o/p: the contours and hierarchy.\n",
    "contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#Sort Contours Descending\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "print(len(contours))\n",
    "\n",
    "\n",
    "#Draw Contours\n",
    "img_contours=np.copy(img)\n",
    "# 3rd parm: To draw all the contours in an image (-1) or To draw an individual contour, say 3th contour (2)\n",
    "# 4th & 5th parm: color and thickness prespectively :)\n",
    "cv2.drawContours(img_contours, contours[0], -1, (255, 0, 0), 5)\n",
    "show_images([img_contours],['Contours'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "image_original = cv2.imread('car/3.jpeg')\n",
    "cv2.imshow(\"Original\", image_original)\n",
    " \n",
    "result = image_original.copy()\n",
    " \n",
    "image = cv2.cvtColor(image_original, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "# lower boundary RED color range values; Hue (0 - 10)\n",
    "lower1 = np.array([0, 100, 20])\n",
    "upper1 = np.array([10, 255, 255])\n",
    "\n",
    "# upper boundary RED color range values; Hue (160 - 180)\n",
    "lower2 = np.array([160,100,20])\n",
    "upper2 = np.array([179,255,255])\n",
    " \n",
    "lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "upper_mask = cv2.inRange(image, lower2, upper2)\n",
    " \n",
    "full_mask = lower_mask + upper_mask;\n",
    " \n",
    "result = cv2.bitwise_and(result, result, mask=full_mask)\n",
    " \n",
    "cv2.imshow('mask', full_mask)\n",
    "cv2.imshow('result', result)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "x: 429.0 y: 658.0\n",
      "90.0\n",
      "[[363 581]\n",
      " [495 581]\n",
      " [495 735]\n",
      " [363 735]]\n",
      "((429.0, 658.0), (154.0, 132.0), 90.0)\n"
     ]
    }
   ],
   "source": [
    "#Getting Contours in image\n",
    "# 1st parm: source image\n",
    "# 2nd parm: contour retrieval mode\n",
    "# 3rd parm: contour approximation method cv2.CHAIN_APPROX_SIMPLE[Memory saved not all points are stored]\n",
    "#o/p: the contours and hierarchy.\n",
    "contours, hierarchy = cv2.findContours(full_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#Sort Contours Descending\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "print(len(contours))\n",
    "# print((contours))\n",
    "\n",
    "\n",
    "#Draw Contours\n",
    "img_contours=np.copy(result)\n",
    "# 3rd parm: To draw all the contours in an image (-1) or To draw an individual contour, say 3th contour (2)\n",
    "# 4th & 5th parm: color and thickness prespectively :)\n",
    "# countors_image=np.copy(image_original)\n",
    "# cv2.drawContours(countors_image, contours[0], -1, (255, 0, 0), 5)\n",
    "# show_images([countors_image],['Contours'])\n",
    "# print(np.shape(countors_image))\n",
    "\n",
    "\n",
    "# print(contours[0])\n",
    "\n",
    "# Draming Rectangle :D\n",
    "rectangle_image=np.copy(image_original)\n",
    "rect = cv2.minAreaRect(contours[0])\n",
    "box = cv2.boxPoints(rect)\n",
    "box = np.int0(box)\n",
    "cv2.drawContours(rectangle_image,[box],0,(0,255,0),10)\n",
    "\n",
    "\n",
    "\n",
    "#Getting Center and angle of rotation of Rectangle\n",
    "((x, y), (width, height), angle_of_rotation) = cv2.minAreaRect(box)\n",
    "print(\"x:\",x,\"y:\",y)\n",
    "print(angle_of_rotation)\n",
    "\n",
    "show_images([rectangle_image],['Car Rectangle'],BGR=True)\n",
    "\n",
    "print(box)\n",
    "print(rect)\n",
    "\n",
    "# print(box.angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found @ x 44  y 302\n"
     ]
    }
   ],
   "source": [
    "# find line of on which car is on\n",
    "xCar=x\n",
    "yCar=y\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    if(on_line (x1,y1,x2,y2,xCar,yCar,maxthershold=20)):\n",
    "        print(\"Found @ x\",x1,\" y\",y1)\n",
    "        image_original[x1-10:x1+10,y1-10:y1+10]=(255,255,255)\n",
    "        #Getting Distance from this Center to the start of the straight line\n",
    "        cv2.imshow(\"Original\", image_original)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
